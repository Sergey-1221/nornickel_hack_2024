Мультимодальный поиск по документам
Данный проект демонстрирует пайплайн для мультимодального анализа документов, содержащих как текстовые данные, так и графические элементы (изображения, схемы, графики). Основная идея – объединить два мира:

Текст: Извлекается либо напрямую из документа, либо с помощью OCR из изображений, затем превращается в эмбеддинги.
Изображения: Генерируются визуальные эмбеддинги с помощью мультимодальной модели (CLIP или другой).
Результат – интерактивное веб-приложение на Streamlit, позволяющее загружать обработанные данные и осуществлять поиск по тексту или по загруженному изображению, находя релевантные чанки документа и связанные с ними изображения.

Возможности
OCR (Оптическое распознавание символов): Автоматически извлекает текст с изображений страниц документа (например, графики или иллюстрации в отчёте).
Текстовые эмбеддинги: Используются модели из sentence-transformers для генерации текстовых векторов.
Изображенительные эмбеддинги: Применяются модели (например, CLIP) для получения векторных представлений изображений.
Мультимодальный поиск: Можно выполнить поиск по текстовому запросу или по загруженному пользователем изображению. Результаты сортируются по косинусному сходству эмбеддингов.
Интерактивный интерфейс на Streamlit: Удобный веб-интерфейс для загрузки данных, запуска поиска и просмотра результатов.
Структура пайплайна
Подготовка данных (Этап 1):

Конвертация PDF в структурированные чанки (текст, метаданные, извлечённые изображения).
Сохранение результатов в JSON.
Генерация эмбеддингов (Этап 2):

Применение OCR к изображениям, если в чанках нет текста.
Генерация текстовых эмбеддингов для чанков.
Генерация эмбеддингов для изображений с помощью CLIP.
Обновление JSON с эмбеддингами.
Мультимодальный поиск:

Загрузка подготовленных данных в Streamlit-приложение.
Ввод текстового запроса или загрузка изображений для поиска.
Получение релевантных чанков и отображение их текста и связанных изображений.
Требования
Python 3.8+

Установленный tesseract-ocr (для OCR):

bash
Копировать код
sudo apt-get update
sudo apt-get install tesseract-ocr
Библиотеки Python:

bash
Копировать код
pip install -r requirements.txt
Пример содержимого requirements.txt:

txt
Копировать код
streamlit
sentence-transformers
torch
torchvision
torchaudio
pytesseract
Pillow
git+https://github.com/openai/CLIP.git
numpy
Установка и запуск
Клонировать репозиторий:

bash
Копировать код
git clone https://github.com/<username>/<repo_name>.git
cd <repo_name>
Установить зависимости:

bash
Копировать код
pip install -r requirements.txt
Подготовить данные:
Выполните скрипты для обработки PDF и генерации эмбеддингов. Предполагается, что у вас есть свой код main_stage1() и main_stage2():

bash
Копировать код
python your_script.py
После выполнения этого шага в папке processed_results_final должен появиться файл document_processed.json.

Запустить Streamlit-приложение:

bash
Копировать код
streamlit run app.py
Откройте указанный в терминале URL (обычно http://localhost:8501) в браузере.

Использование приложения
Загрузите обработанные данные, нажав на кнопку "Загрузить данные".
При успешной загрузке вы можете:
Перейти на вкладку "Поиск по тексту", ввести текстовый запрос и получить релевантные результаты.
Перейти на вкладку "Поиск по изображению", загрузить картинку и получить похожие чанки и изображения из документа.
Пролистать результаты с помощью слайдера и просматривать извлечённый текст и изображения.
Пример
Допустим, у вас есть PDF-отчёт компании с графиками и текстом. После обработки вы можете ввести, например, запрос "Nickel mining" и получить чанк текста, описывающий процессы добычи никеля, а также связанные изображения (графики добычи или финансирования).

Архитектура проекта
app.py: основной файл Streamlit-приложения.
processed_results_final/document_processed.json: результаты обработки, содержащие чанки, их текст, метаданные, пути к изображениям и эмбеддинги.
nornickel_hack_2024/: директория, содержащая логику подготовки данных (конвертация PDF, OCR, извлечение эмбеддингов), если это ваш внутренний репозиторий.
Дальнейшее развитие
Добавление возможности фильтрации по метаданным (страница, заголовок).
Улучшение качества OCR, настройка языка.
Интеграция более продвинутых мультимодальных моделей или векторных баз данных для быстрого поиска.
Расширение интерфейса для аннотаций и сохранения результатов 
