{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-07T23:01:36.573907Z",
     "start_time": "2024-12-07T23:01:17.907829Z"
    }
   },
   "source": [
    "from transformers import Qwen2VLForConditionalGeneration, Qwen2VLProcessor, BitsAndBytesConfig\n",
    "from qwen_vl_utils import process_vision_info\n",
    "import torch\n",
    "\n",
    "# BitsAndBytesConfig int-4 config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# Load model and tokenizer\n",
    "vl_model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2-VL-7B-Instruct\", device_map=\"auto\", torch_dtype=torch.bfloat16, quantization_config=bnb_config\n",
    ")\n",
    "vl_model.eval()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f462be048e254a748155f7881d0dba2b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Qwen2VLForConditionalGeneration(\n",
       "  (visual): Qwen2VisionTransformerPretrainedModel(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)\n",
       "    )\n",
       "    (rotary_pos_emb): VisionRotaryEmbedding()\n",
       "    (blocks): ModuleList(\n",
       "      (0-31): 32 x Qwen2VLVisionBlock(\n",
       "        (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): VisionSdpaAttention(\n",
       "          (qkv): Linear4bit(in_features=1280, out_features=3840, bias=True)\n",
       "          (proj): Linear4bit(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (mlp): VisionMlp(\n",
       "          (fc1): Linear4bit(in_features=1280, out_features=5120, bias=True)\n",
       "          (act): QuickGELUActivation()\n",
       "          (fc2): Linear4bit(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (merger): PatchMerger(\n",
       "      (ln_q): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear4bit(in_features=5120, out_features=5120, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear4bit(in_features=5120, out_features=3584, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (model): Qwen2VLModel(\n",
       "    (embed_tokens): Embedding(152064, 3584)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen2VLDecoderLayer(\n",
       "        (self_attn): Qwen2VLSdpaAttention(\n",
       "          (q_proj): Linear4bit(in_features=3584, out_features=3584, bias=True)\n",
       "          (k_proj): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
       "          (v_proj): Linear4bit(in_features=3584, out_features=512, bias=True)\n",
       "          (o_proj): Linear4bit(in_features=3584, out_features=3584, bias=False)\n",
       "          (rotary_emb): Qwen2VLRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=3584, out_features=18944, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=18944, out_features=3584, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2VLRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T23:01:37.991295Z",
     "start_time": "2024-12-07T23:01:36.582907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "min_pixels = 448 * 448\n",
    "max_pixels = 896 * 896 \n",
    "vl_model_processor = Qwen2VLProcessor.from_pretrained(\n",
    "    \"Qwen/Qwen2-VL-7B-Instruct\", min_pixels=min_pixels, max_pixels=max_pixels\n",
    ")"
   ],
   "id": "3a345f34911df220",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T20:57:42.194575Z",
     "start_time": "2024-12-07T20:57:41.819880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Пример текстов для получения эмбендингов\n",
    "texts = [\n",
    "    \"Это пример текста для извлечения эмбеддингов.\",\n",
    "    \"Еще один образец текстового описания.\"\n",
    "]\n",
    "\n",
    "# Предобработка текста\n",
    "text_inputs = vl_model_processor(text=texts, padding=True, return_tensors=\"pt\").to(vl_model.device)\n",
    "\n",
    "# Прогон через модель с получением скрытых состояний\n",
    "with torch.no_grad():\n",
    "    outputs = vl_model(\n",
    "        **text_inputs,\n",
    "        output_hidden_states=True,  # Запрос скрытых состояний\n",
    "        return_dict=True\n",
    "    )\n",
    "\n",
    "# Извлекаем последний скрытый слой\n",
    "last_hidden_states = outputs.hidden_states[-1]  # [batch_size, seq_length, hidden_dim]\n",
    "\n",
    "# Маска для токенов (чтобы не учитывать паддинговые токены при вычислении среднего)\n",
    "attention_mask = text_inputs['attention_mask']\n",
    "expanded_mask = attention_mask.unsqueeze(-1).expand(last_hidden_states.size()).float()  # [batch_size, seq_length, hidden_dim]\n",
    "\n",
    "# Вычисляем средний эмбеддинг по непаддинговым токенам\n",
    "sum_embeddings = torch.sum(last_hidden_states * expanded_mask, dim=1)\n",
    "sum_mask = torch.clamp(attention_mask.sum(dim=1, keepdim=True), min=1e-9)  # чтобы не делить на ноль\n",
    "mean_embeddings = sum_embeddings / sum_mask\n",
    "\n",
    "# mean_embeddings будет размерностью [batch_size, hidden_dim] и может использоваться в RAG для индексации.\n",
    "mean_embeddings = mean_embeddings.detach().cpu().numpy()"
   ],
   "id": "ab9eff1b8a0addb0",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T20:41:25.140289Z",
     "start_time": "2024-12-07T20:41:25.137286Z"
    }
   },
   "cell_type": "code",
   "source": "3584",
   "id": "12550fd02a2f36f3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 92211,  24634, 131616,  70895,   1478,  19849,  23064, 124991,  55757,\n",
       "          18492,  20928,   6442, 132705,  70338,  15390,   6715,     13],\n",
       "        [151643, 151643, 151643, 151643, 151643, 151643,  55091, 125103, 129385,\n",
       "         127273, 126499,  70895, 130928,   8215,  29665,  38180,     13]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T21:21:29.781614Z",
     "start_time": "2024-12-07T21:21:29.692536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "image = Image.open(\"1.jpg\")\n",
    "inputs = vl_model_processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = vl_model.get_image_features(**inputs) \n",
    "    # Если метод get_image_features не доступен, смотрите документацию модели.\n",
    "    # Альтернативно может быть:\n",
    "    # outputs = model(**inputs)\n",
    "\n",
    "image_embeddings = outputs"
   ],
   "id": "e32231aa4bbb3646",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'NoneType' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[35], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mPIL\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Image\n\u001B[0;32m      2\u001B[0m image \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mopen(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1.jpg\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m inputs \u001B[38;5;241m=\u001B[39m \u001B[43mvl_model_processor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mimage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m      6\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m vl_model\u001B[38;5;241m.\u001B[39mget_image_features(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39minputs) \n",
      "File \u001B[1;32m~\\Desktop\\MLLM\\venv\\lib\\site-packages\\transformers\\models\\qwen2_vl\\processing_qwen2_vl.py:135\u001B[0m, in \u001B[0;36mQwen2VLProcessor.__call__\u001B[1;34m(self, images, text, videos, **kwargs)\u001B[0m\n\u001B[0;32m    133\u001B[0m index \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m    134\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(text)):\n\u001B[1;32m--> 135\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m<|image_pad|>\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtext\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m:\n\u001B[0;32m    136\u001B[0m         text[i] \u001B[38;5;241m=\u001B[39m text[i]\u001B[38;5;241m.\u001B[39mreplace(\n\u001B[0;32m    137\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<|image_pad|>\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<|placeholder|>\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m*\u001B[39m (image_grid_thw[index]\u001B[38;5;241m.\u001B[39mprod() \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m merge_length), \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    138\u001B[0m         )\n\u001B[0;32m    139\u001B[0m         index \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "\u001B[1;31mTypeError\u001B[0m: argument of type 'NoneType' is not iterable"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T23:04:13.504231Z",
     "start_time": "2024-12-07T23:04:00.274856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import base64\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "def get_text_embeddings(texts: list[str]) -> np.ndarray:\n",
    "    # Предобработка текста\n",
    "    text_inputs = vl_model_processor(text=texts, padding=True, return_tensors=\"pt\").to(vl_model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = vl_model(\n",
    "            **text_inputs,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True\n",
    "        )\n",
    "    last_hidden_states = outputs.hidden_states[-1]  # [batch_size, seq_length, hidden_dim]\n",
    "\n",
    "    attention_mask = text_inputs['attention_mask']\n",
    "    expanded_mask = attention_mask.unsqueeze(-1).expand(last_hidden_states.size()).float()\n",
    "    sum_embeddings = torch.sum(last_hidden_states * expanded_mask, dim=1)\n",
    "    sum_mask = torch.clamp(attention_mask.sum(dim=1, keepdim=True), min=1e-9)\n",
    "    mean_embeddings = sum_embeddings / sum_mask\n",
    "    return mean_embeddings.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "\n",
    "def get_image_embeddings(image_url: str):\n",
    "    response = requests.get(image_url)\n",
    "    image_bytes = response.content\n",
    "    image = Image.open(BytesIO(image_bytes)).convert(\"RGB\")\n",
    "\n",
    "    # Определяем формат или используем \"jpeg\" по умолчанию\n",
    "    image_format = image.format.lower() if image.format else \"jpeg\"\n",
    "    base64_image = base64.b64encode(image_bytes).decode('utf-8')\n",
    "    data_url = f\"data:image/{image_format};base64,{base64_image}\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"image\": data_url\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Опишите содержимое этого изображения: <|image|>\"\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Генерируем текстовый prompt\n",
    "    text = vl_model_processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)\n",
    "\n",
    "    # Обрабатываем визуальную информацию\n",
    "    image_inputs, video_inputs = process_vision_info(messages)\n",
    "\n",
    "    # Получаем готовые входы для модели\n",
    "    inputs = vl_model_processor(\n",
    "        text=[text],\n",
    "        images=image_inputs,\n",
    "        videos=video_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(vl_model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = vl_model(\n",
    "            **inputs,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=True\n",
    "        )\n",
    "\n",
    "    # Последний слой скрытых состояний\n",
    "    last_hidden_states = outputs.hidden_states[-1]  # [batch_size, seq_length, hidden_dim]\n",
    "\n",
    "    # Находим токены изображения в input_ids\n",
    "    image_token_id = vl_model.config.image_token_id\n",
    "    image_token_mask = (inputs[\"input_ids\"] == image_token_id)  # bool mask для всех позиций токенов изображения\n",
    "\n",
    "    # Усредняем по всем токенам, соответствующим изображению\n",
    "    # Если изображение одно, то будет одна группа image-токенов.\n",
    "    # Если image_token_mask пустой (нет токенов изображения), будет ошибка деления на ноль.\n",
    "    # Предполагается, что <|image|> есть в тексте.\n",
    "    image_token_count = image_token_mask.sum(dim=1, keepdim=True).clamp_min(1e-9)\n",
    "    image_embeddings = (last_hidden_states * image_token_mask.unsqueeze(-1)).sum(dim=1) / image_token_count\n",
    "\n",
    "    return image_embeddings.detach().cpu().numpy()\n",
    "\n",
    "for i in range(20):\n",
    "    # Пример использования\n",
    "    image_url = \"https://i0.wp.com/quorace.com/wp-content/uploads/2016/11/%D0%93%D1%801.jpg\"\n",
    "    image_embeds = get_image_embeddings(image_url)\n",
    "    print(\"Эмбеддинги изображения:\", image_embeds.shape)\n",
    "# Теперь у вас есть векторы text_embeds и image_embeds, которые можно использовать в RAG (например, занести в векторное хранилище)."
   ],
   "id": "58034cae587fa6f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эмбеддинги изображения: (1, 3584)\n",
      "Эмбеддинги изображения: (1, 3584)\n",
      "Эмбеддинги изображения: (1, 3584)\n",
      "Эмбеддинги изображения: (1, 3584)\n",
      "Эмбеддинги изображения: (1, 3584)\n",
      "Эмбеддинги изображения: (1, 3584)\n",
      "Эмбеддинги изображения: (1, 3584)\n",
      "Эмбеддинги изображения: (1, 3584)\n",
      "Эмбеддинги изображения: (1, 3584)\n",
      "Эмбеддинги изображения: (1, 3584)\n",
      "Эмбеддинги изображения: (1, 3584)\n",
      "Эмбеддинги изображения: (1, 3584)\n",
      "Эмбеддинги изображения: (1, 3584)\n",
      "Эмбеддинги изображения: (1, 3584)\n",
      "Эмбеддинги изображения: (1, 3584)\n",
      "Эмбеддинги изображения: (1, 3584)\n",
      "Эмбеддинги изображения: (1, 3584)\n",
      "Эмбеддинги изображения: (1, 3584)\n",
      "Эмбеддинги изображения: (1, 3584)\n",
      "Эмбеддинги изображения: (1, 3584)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T23:03:33.004176Z",
     "start_time": "2024-12-07T23:01:49.145628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"image\",\n",
    "                \"image\": \"https://i0.wp.com/quorace.com/wp-content/uploads/2016/11/%D0%93%D1%801.jpg\",\n",
    "            },\n",
    "            {\"type\": \"text\", \"text\": \"Что изображено на фото?\"},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "text = vl_model_processor.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "for i in range(20):\n",
    "    image_inputs, video_inputs = process_vision_info(messages)\n",
    "    inputs = vl_model_processor(\n",
    "        text=[text],\n",
    "        images=image_inputs,\n",
    "        videos=video_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    inputs = inputs.to(\"cuda\")\n",
    "    \n",
    "    # Inference: Generation of the output\n",
    "    generated_ids = vl_model.generate(**inputs, max_new_tokens=128)\n",
    "    generated_ids_trimmed = [\n",
    "        out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    output_text = vl_model_processor.batch_decode(\n",
    "        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )\n",
    "    print(output_text)"
   ],
   "id": "fb2290163c47f243",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['На фото изображена диаграмма, представляющая данные в виде столбиков. Диаграмма имеет четыре столбика, каждый из которых соответствует определенному значению. Столбик, соответствующий \"плат\", имеет самое высокое значение, достигающее 50%. Столбик, соответствующий \"3\", имеет значение около 10%. Столбик, соответствующий \"плат\", имеет значение около 20%. Столбик, соответствующий \"плат\", имеет значение около 5%.']\n",
      "['На фото изображена диаграмма, представляющая данные в виде столбиков. Диаграмма имеет четыре столбика, каждый из которых соответствует определенному значению. Столбик, соответствующий \"плат\", имеет самое высокое значение, достигающее 50%. Столбик, соответствующий \"3\", имеет значение около 10%. Столбик, соответствующий \"плат\", имеет значение около 20%. Столбик, соответствующий \"плат\", имеет значение около 5%.']\n",
      "['На фото изображена диаграмма, представляющая данные в виде столбиков. Диаграмма имеет четыре столбика, каждый из которых соответствует определенному значению. Столбик, соответствующий \"плат\", имеет самое высокое значение, достигающее 50%. Столбик, соответствующий \"3\", имеет значение около 10%. Столбик, соответствующий \"плат\", имеет значение около 20%. Столбик, соответствующий \"плат\", имеет значение около 5%.']\n",
      "['На фото изображена диаграмма, представляющая данные в виде столбиков. Диаграмма имеет четыре столбика, каждый из которых соответствует определенному значению. Столбик, соответствующий \"плат\", имеет самое высокое значение, достигающее 50%. Столбик, соответствующий \"3\", имеет значение около 10%. Столбик, соответствующий \"плат\", имеет значение около 20%. Столбик, соответствующий \"плат\", имеет значение около 5%.']\n",
      "['На фото изображена диаграмма, представляющая данные в виде столбиков. Диаграмма имеет четыре столбика, каждый из которых соответствует определенному значению. Столбик, соответствующий \"плат\", имеет самое высокое значение, достигающее 50%. Столбик, соответствующий \"3\", имеет значение около 10%. Столбик, соответствующий \"плат\", имеет значение около 20%. Столбик, соответствующий \"плат\", имеет значение около 5%.']\n",
      "['На фото изображена диаграмма, представляющая данные в виде столбиков. Диаграмма имеет четыре столбика, каждый из которых соответствует определенному значению. Столбик, соответствующий \"плат\", имеет самое высокое значение, достигающее 50%. Столбик, соответствующий \"3\", имеет значение около 10%. Столбик, соответствующий \"плат\", имеет значение около 20%. Столбик, соответствующий \"плат\", имеет значение около 5%.']\n",
      "['На фото изображена диаграмма, представляющая данные в виде столбиков. Диаграмма имеет четыре столбика, каждый из которых соответствует определенному значению. Столбик, соответствующий \"плат\", имеет самое высокое значение, достигающее 50%. Столбик, соответствующий \"3\", имеет значение около 10%. Столбик, соответствующий \"плат\", имеет значение около 20%. Столбик, соответствующий \"плат\", имеет значение около 5%.']\n",
      "['На фото изображена диаграмма, представляющая данные в виде столбиков. Диаграмма имеет четыре столбика, каждый из которых соответствует определенному значению. Столбик, соответствующий \"плат\", имеет самое высокое значение, достигающее 50%. Столбик, соответствующий \"3\", имеет значение около 10%. Столбик, соответствующий \"плат\", имеет значение около 20%. Столбик, соответствующий \"плат\", имеет значение около 5%.']\n",
      "['На фото изображена диаграмма, представляющая данные в виде столбиков. Диаграмма имеет четыре столбика, каждый из которых соответствует определенному значению. Столбик, соответствующий \"плат\", имеет самое высокое значение, достигающее 50%. Столбик, соответствующий \"3\", имеет значение около 10%. Столбик, соответствующий \"плат\", имеет значение около 20%. Столбик, соответствующий \"плат\", имеет значение около 5%.']\n",
      "['На фото изображена диаграмма, представляющая данные в виде столбиков. Диаграмма имеет четыре столбика, каждый из которых соответствует определенному значению. Столбик, соответствующий \"плат\", имеет самое высокое значение, достигающее 50%. Столбик, соответствующий \"3\", имеет значение около 10%. Столбик, соответствующий \"плат\", имеет значение около 20%. Столбик, соответствующий \"плат\", имеет значение около 5%.']\n",
      "['На фото изображена диаграмма, представляющая данные в виде столбиков. Диаграмма имеет четыре столбика, каждый из которых соответствует определенному значению. Столбик, соответствующий \"плат\", имеет самое высокое значение, достигающее 50%. Столбик, соответствующий \"3\", имеет значение около 10%. Столбик, соответствующий \"плат\", имеет значение около 20%. Столбик, соответствующий \"плат\", имеет значение около 5%.']\n",
      "['На фото изображена диаграмма, представляющая данные в виде столбиков. Диаграмма имеет четыре столбика, каждый из которых соответствует определенному значению. Столбик, соответствующий \"плат\", имеет самое высокое значение, достигающее 50%. Столбик, соответствующий \"3\", имеет значение около 10%. Столбик, соответствующий \"плат\", имеет значение около 20%. Столбик, соответствующий \"плат\", имеет значение около 5%.']\n",
      "['На фото изображена диаграмма, представляющая данные в виде столбиков. Диаграмма имеет четыре столбика, каждый из которых соответствует определенному значению. Столбик, соответствующий \"плат\", имеет самое высокое значение, достигающее 50%. Столбик, соответствующий \"3\", имеет значение около 10%. Столбик, соответствующий \"плат\", имеет значение около 20%. Столбик, соответствующий \"плат\", имеет значение около 5%.']\n",
      "['На фото изображена диаграмма, представляющая данные в виде столбиков. Диаграмма имеет четыре столбика, каждый из которых соответствует определенному значению. Столбик, соответствующий \"плат\", имеет самое высокое значение, достигающее 50%. Столбик, соответствующий \"3\", имеет значение около 10%. Столбик, соответствующий \"плат\", имеет значение около 20%. Столбик, соответствующий \"плат\", имеет значение около 5%.']\n",
      "['На фото изображена диаграмма, представляющая данные в виде столбиков. Диаграмма имеет четыре столбика, каждый из которых соответствует определенному значению. Столбик, соответствующий \"плат\", имеет самое высокое значение, достигающее 50%. Столбик, соответствующий \"3\", имеет значение около 10%. Столбик, соответствующий \"плат\", имеет значение около 20%. Столбик, соответствующий \"плат\", имеет значение около 5%.']\n",
      "['На фото изображена диаграмма, представляющая данные в виде столбиков. Диаграмма имеет четыре столбика, каждый из которых соответствует определенному значению. Столбик, соответствующий \"плат\", имеет самое высокое значение, достигающее 50%. Столбик, соответствующий \"3\", имеет значение около 10%. Столбик, соответствующий \"плат\", имеет значение около 20%. Столбик, соответствующий \"плат\", имеет значение около 5%.']\n",
      "['На фото изображена диаграмма, представляющая данные в виде столбиков. Диаграмма имеет четыре столбика, каждый из которых соответствует определенному значению. Столбик, соответствующий \"плат\", имеет самое высокое значение, достигающее 50%. Столбик, соответствующий \"3\", имеет значение около 10%. Столбик, соответствующий \"плат\", имеет значение около 20%. Столбик, соответствующий \"плат\", имеет значение около 5%.']\n",
      "['На фото изображена диаграмма, представляющая данные в виде столбиков. Диаграмма имеет четыре столбика, каждый из которых соответствует определенному значению. Столбик, соответствующий \"плат\", имеет самое высокое значение, достигающее 50%. Столбик, соответствующий \"3\", имеет значение около 10%. Столбик, соответствующий \"плат\", имеет значение около 20%. Столбик, соответствующий \"плат\", имеет значение около 5%.']\n",
      "['На фото изображена диаграмма, представляющая данные в виде столбиков. Диаграмма имеет четыре столбика, каждый из которых соответствует определенному значению. Столбик, соответствующий \"плат\", имеет самое высокое значение, достигающее 50%. Столбик, соответствующий \"3\", имеет значение около 10%. Столбик, соответствующий \"плат\", имеет значение около 20%. Столбик, соответствующий \"плат\", имеет значение около 5%.']\n",
      "['На фото изображена диаграмма, представляющая данные в виде столбиков. Диаграмма имеет четыре столбика, каждый из которых соответствует определенному значению. Столбик, соответствующий \"плат\", имеет самое высокое значение, достигающее 50%. Столбик, соответствующий \"3\", имеет значение около 10%. Столбик, соответствующий \"плат\", имеет значение около 20%. Столбик, соответствующий \"плат\", имеет значение около 5%.']\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T23:03:33.518684Z",
     "start_time": "2024-12-07T23:03:33.501687Z"
    }
   },
   "cell_type": "code",
   "source": "1.43  13",
   "id": "6f4324d473013ccb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ae1903ab25a85cdf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
